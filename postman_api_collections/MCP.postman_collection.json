{
  "info": {
    "_postman_id": "638217d5-c664-445c-a953-7da2dcc41209",
    "name": "MCP",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json",
    "_exporter_id": "45403895"
  },
  "item": [
    {
      "name": "MCP - Client APIs",
      "item": [
        {
          "name": "Gemini",
          "item": [
            {
              "name": "Non-Stream Api",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\r\n    \"selected_server_credentials\": {\r\n        \"WORDPRESS\": {\r\n            \"siteUrl\": \"\",\r\n            \"username\": \"\",\r\n            \"password\": \"\"\r\n        }\r\n        //  \"G_DRIVE\": {\r\n        //     \"web\": {\r\n        //         \"client_id\":\"\",\r\n        //         \"client_secret\":\"\",\r\n        //         \"refresh_token\": \"\",\r\n        //         \"access_token\": \"\"\r\n        //     }\r\n        // }\r\n    },\r\n    \"client_details\": {\r\n        \"api_key\": \"\",\r\n        \"temperature\": 0.1,\r\n        \"max_token\":20000,\r\n        \"input\": \"use the credentials which user already provided ,on my G Drive, search for 'POA June 2025' google sheet and let me know whether available or not if available get the some data\",\r\n        \"input_type\": \"text\",\r\n        \"prompt\": \"you are a helpful assistant\",\r\n        \"chat_model\": \"gemini-2.0-flash-lite\",\r\n        \"chat_history\": [\r\n            {\r\n                \"role\": \"user\",\r\n                \"content\": \"Hii\"\r\n            }\r\n        ]\r\n    },\r\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\r\n    \"selected_servers\": [\r\n        \"WORDPRESS\"\r\n    ]\r\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-js-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-js-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api -python",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\r\n    \"selected_server_credentials\": {\r\n        \"MCP-GSUITE\": {\r\n            \"token\": \"\",\r\n            \"refresh_token\": \"\",\r\n            \"client_id\": \"\",\r\n            \"client_secret\": \"\"\r\n        }\r\n        // \"WORDPRESS\": {\r\n        //     \"siteUrl\": \"\",\r\n        //     \"username\": \"\",\r\n        //     \"password\": \"\"\r\n        // }\r\n        //  \"G_DRIVE\": {\r\n        //     \"web\": {\r\n        //         \"client_id\":\"\",\r\n        //         \"client_secret\":\"\",\r\n        //         \"refresh_token\": \"\",\r\n        //         \"access_token\": \"\"\r\n        //     }\r\n        // }\r\n    },\r\n    \"client_details\": {\r\n        \"api_key\": \"\",\r\n        \"temperature\": 0.1,\r\n        \"max_token\": 20000,\r\n        \"input\": \"get the recent one email\",\r\n        \"input_type\": \"text\",\r\n        \"prompt\": \"you are a helpful assistant\",\r\n        \"chat_model\": \"gemini-2.0-flash\",\r\n        \"chat_history\": [\r\n            {\r\n                \"role\": \"user\",\r\n                \"content\": \"Hii\"\r\n            }\r\n        ]\r\n    },\r\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\r\n    \"selected_servers\": [\r\n        \"MCP-GSUITE\"\r\n    ]\r\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Stream API",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\r\n    \"selected_server_credentials\": {\r\n        \"WORDPRESS\": {\r\n            \"siteUrl\": \"\",\r\n            \"username\": \"\",\r\n            \"password\": \"\"\r\n        }\r\n        //  \"G_DRIVE\": {\r\n        //     \"web\": {\r\n        //         \"client_id\":\"\",\r\n        //         \"client_secret\":\"\",\r\n        //         \"refresh_token\": \"\",\r\n        //         \"access_token\": \"\"\r\n        //     }\r\n        // }\r\n    },\r\n    \"client_details\": {\r\n        \"api_key\": \"\",\r\n        \"temperature\": 0.1,\r\n        \"max_token\":20000,\r\n        \"input\": \"get the recent published post\",\r\n        \"input_type\": \"text\",\r\n        \"prompt\": \"you are a helpful assistant\",\r\n        \"chat_model\": \"gemini-2.0-flash-lite\",\r\n        \"chat_history\": [\r\n            {\r\n                \"role\": \"user\",\r\n                \"content\": \"Hii\"\r\n            }\r\n        ]\r\n    },\r\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\r\n    \"selected_servers\": [\r\n        \"WORDPRESS\"\r\n    ]\r\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-js-host}}/api/v1/mcp/process_message_stream",
                  "host": [
                    "{{dev-js-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message_stream"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - NumPy MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"NUMPY_MCP\": {}\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Calculate the eigenvalues and eigenvectors of the matrix [[4, 2], [1, 3]]. Also find the determinant and inverse of this matrix.\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a helpful mathematical assistant that can perform complex calculations using NumPy\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": [\n            {\n                \"role\": \"user\",\n                \"content\": \"I need help with matrix calculations\"\n            }\n        ]\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"NUMPY_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - Neo4j MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"NEO4J_MCP\": {\n            \"uri\": \"bolt://localhost:7687\",\n            \"username\": \"neo4j\",\n            \"password\": \"your-password\",\n            \"database\": \"neo4j\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Create a social network graph. First create nodes for Alice (age: 30), Bob (age: 25), and Charlie (age: 35) with Person labels. Then create friendship relationships between Alice-Bob and Bob-Charlie. Finally, find the shortest path between Alice and Charlie.\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a graph database expert using Neo4j for social network analysis\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"NEO4J_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Send a text message 'Hello from LINE MCP Server!' to user ID U1234567890\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE messaging assistant that can send messages and rich content\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - DAVINCI MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"DAVINCI_MCP\": {}\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"List all DaVinci Resolve projects\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a DaVinci Resolve automation assistant\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"DAVINCI_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        },
        {
          "name": "Azure OpenAi",
          "item": [
            {
              "name": "Non-Stream Api - LINE MCP User Profile",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Get the profile information for user ID U1234567890\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE user management assistant that can retrieve user profiles and information\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        },
        {
          "name": "Azure OpenAi",
          "item": [
            {
              "name": "Non-Stream Api - LINE MCP Flex Message",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Send a flex message to user U1234567890 with a simple card containing title 'Welcome to MCP!' and description 'Explore our powerful LINE integration features.'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE flex message specialist that creates beautiful custom layouts\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP Broadcast",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Broadcast a welcome message saying 'Welcome to our LINE MCP Integration! We can help you with mathematical calculations, email management, and rich messaging features.'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE broadcast messaging assistant\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"NEO4J_MCP\": {\n            \"uri\": \"bolt://localhost:7687\",\n            \"username\": \"neo4j\",\n            \"password\": \"your-password\",\n            \"database\": \"neo4j\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Create a social network graph. First create nodes for Alice (age: 30), Bob (age: 25), and Charlie (age: 35) with Person labels. Then create friendship relationships between Alice-Bob and Bob-Charlie. Finally, find the shortest path between Alice and Charlie.\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a graph database expert using Neo4j for social network analysis\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"NEO4J_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - MCP-GSUITE",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"MCP-GSUITE\": {\n            \"token\": \"\",\n            \"refresh_token\": \"\",\n            \"client_id\": \"\",\n            \"client_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"get the recent one email\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a helpful assistant\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": [\n            {\n                \"role\": \"user\",\n                \"content\": \"Hii\"\n            }\n        ]\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"MCP-GSUITE\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        },
        {
          "name": "Openai",
          "item": [
            {
              "name": "Non-Stream Api - LINE MCP Azure",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"endpoint\": \"\",\n        \"deployment_id\": \"gpt-4o\",\n        \"api_version\": \"\",\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"input\": \"Send a carousel message to user U1234567890 with three cards: Card 1 - 'Math Helper' with description 'Get mathematical calculations' and a button to 'Calculate Matrix', Card 2 - 'Email Assistant' with description 'Manage your emails' and a button to 'Check Emails', Card 3 - 'General Help' with description 'Get general assistance' and a button to 'Get Help'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a comprehensive assistant that can send rich LINE messages, perform mathematical calculations, and manage emails\",\n        \"chat_model\": \"gpt-4o\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_AZURE_AI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        },
        {
          "name": "OpenAI",
          "item": [
            {
              "name": "Non-Stream Api - LINE MCP OpenAI",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"input\": \"Send an image message to user U1234567890 with image URL 'https://example.com/sample-image.jpg'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE image messaging assistant\",\n        \"chat_model\": \"gpt-4o\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_OPENAI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        }
      ]
    }
  ]
}
