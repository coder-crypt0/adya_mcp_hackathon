{
  "info": {
    "_postman_id": "638217d5-c664-445c-a953-7da2dcc41209",
    "name": "MCP",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json",
    "_exporter_id": "45403895"
  },
  "item": [
    {
      "name": "MCP - Client APIs",
      "item": [
        {
          "name": "Gemini",
          "item": [
            {
              "name": "Non-Stream Api - NumPy MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"NUMPY_MCP\": {}\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Calculate the eigenvalues and eigenvectors of the matrix [[4, 2], [1, 3]]. Also find the determinant and inverse of this matrix.\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a helpful mathematical assistant that can perform complex calculations using NumPy\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": [\n            {\n                \"role\": \"user\",\n                \"content\": \"I need help with matrix calculations\"\n            }\n        ]\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"NUMPY_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP Send Text",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Send a text message 'Hello from LINE MCP Server!' to user ID U1234567890\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE messaging assistant that can send messages and rich content\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP Rich Message",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Send a buttons template to user U1234567890 with title 'Choose an option', text 'What would you like to do?', and buttons for 'View Profile' (message action), 'Visit Website' (URI action to https://example.com), and 'Get Help' (postback action with data=help_request)\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE messaging assistant specialized in sending rich interactive content\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP User Profile",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Get the profile information for user ID U1234567890\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE user management assistant that can retrieve user profiles and information\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP Flex Message",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Send a flex message to user U1234567890 with a simple card containing title 'Welcome to MCP!' and description 'Explore our powerful LINE integration features.'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE flex message specialist that creates beautiful custom layouts\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - LINE MCP Broadcast",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Broadcast a welcome message saying 'Welcome to our LINE MCP Integration! We can help you with mathematical calculations, email management, and rich messaging features.'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE broadcast messaging assistant\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - Neo4j MCP",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"NEO4J_MCP\": {\n            \"uri\": \"bolt://localhost:7687\",\n            \"username\": \"neo4j\",\n            \"password\": \"your-password\",\n            \"database\": \"neo4j\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"Create a social network graph. First create nodes for Alice (age: 30), Bob (age: 25), and Charlie (age: 35) with Person labels. Then create friendship relationships between Alice-Bob and Bob-Charlie. Finally, find the shortest path between Alice and Charlie.\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a graph database expert using Neo4j for social network analysis\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"NEO4J_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            },
            {
              "name": "Non-Stream Api - MCP-GSUITE",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"MCP-GSUITE\": {\n            \"token\": \"\",\n            \"refresh_token\": \"\",\n            \"client_id\": \"\",\n            \"client_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"max_token\": 20000,\n        \"input\": \"get the recent one email\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a helpful assistant\",\n        \"chat_model\": \"gemini-2.0-flash\",\n        \"chat_history\": [\n            {\n                \"role\": \"user\",\n                \"content\": \"Hii\"\n            }\n        ]\n    },\n    \"selected_client\": \"MCP_CLIENT_GEMINI\",\n    \"selected_servers\": [\n        \"MCP-GSUITE\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        },
        {
          "name": "Azure OpenAI",
          "item": [
            {
              "name": "Non-Stream Api - LINE MCP Azure",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"endpoint\": \"\",\n        \"deployment_id\": \"gpt-4o\",\n        \"api_version\": \"\",\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"input\": \"Send a carousel message to user U1234567890 with three cards: Card 1 - 'Math Helper' with description 'Get mathematical calculations' and a button to 'Calculate Matrix', Card 2 - 'Email Assistant' with description 'Manage your emails' and a button to 'Check Emails', Card 3 - 'General Help' with description 'Get general assistance' and a button to 'Get Help'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a comprehensive assistant that can send rich LINE messages, perform mathematical calculations, and manage emails\",\n        \"chat_model\": \"gpt-4o\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_AZURE_AI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"
                  ],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        },
        {
          "name": "OpenAI",
          "item": [
            {
              "name": "Non-Stream Api - LINE MCP OpenAI",
              "request": {
                "method": "POST",
                "header": [],
                "body": {
                  "mode": "raw",
                  "raw": "{\n    \"selected_server_credentials\": {\n        \"LINE_MCP\": {\n            \"channel_access_token\": \"\",\n            \"channel_secret\": \"\"\n        }\n    },\n    \"client_details\": {\n        \"api_key\": \"\",\n        \"temperature\": 0.1,\n        \"input\": \"Send an image message to user U1234567890 with image URL 'https://example.com/sample-image.jpg'\",\n        \"input_type\": \"text\",\n        \"prompt\": \"you are a LINE image messaging assistant\",\n        \"chat_model\": \"gpt-4o\",\n        \"chat_history\": []\n    },\n    \"selected_client\": \"MCP_CLIENT_OPENAI\",\n    \"selected_servers\": [\n        \"LINE_MCP\"\n    ]\n}",
                  "options": {
                    "raw": {
                      "language": "json"
                    }
                  }
                },
                "url": {
                  "raw": "{{dev-python-host}}/api/v1/mcp/process_message",
                  "host": [
                    "{{dev-python-host}}"],
                  "path": [
                    "api",
                    "v1",
                    "mcp",
                    "process_message"
                  ]
                }
              },
              "response": []
            }
          ]
        }
      ]
    }
  ]
}
